{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyM6IjIda+PAjPCkbNWKkdnb",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/btoneil2021/Search-Minecraft-Wiki/blob/main/MinecraftWikiScraper.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SDH7j7ZgiyLT"
      },
      "outputs": [],
      "source": [
        "'''\n",
        "HOW TO USE:\n",
        "1. Type API key below\n",
        "2. Run\n",
        "'''\n",
        "api_key = \"[INSERT YOUR API KEY HERE]\""
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1 (and 2 I guess). Scrape Data off Minecraft Wiki"
      ],
      "metadata": {
        "id": "ivhm8ZLsjQAx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%shell\n",
        "pip install chromedriver_autoinstaller\n",
        "pip install selenium"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UgLU7xGtrfIH",
        "outputId": "d09a6f0a-878f-4417-dd3d-3547a7f7fb5a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting chromedriver_autoinstaller\n",
            "  Downloading chromedriver_autoinstaller-0.6.4-py3-none-any.whl (7.6 kB)\n",
            "Requirement already satisfied: packaging>=23.1 in /usr/local/lib/python3.10/dist-packages (from chromedriver_autoinstaller) (24.1)\n",
            "Installing collected packages: chromedriver_autoinstaller\n",
            "Successfully installed chromedriver_autoinstaller-0.6.4\n",
            "Collecting selenium\n",
            "  Downloading selenium-4.22.0-py3-none-any.whl (9.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.4/9.4 MB\u001b[0m \u001b[31m46.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: urllib3[socks]<3,>=1.26 in /usr/local/lib/python3.10/dist-packages (from selenium) (2.0.7)\n",
            "Collecting trio~=0.17 (from selenium)\n",
            "  Downloading trio-0.26.0-py3-none-any.whl (475 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m475.7/475.7 kB\u001b[0m \u001b[31m38.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting trio-websocket~=0.9 (from selenium)\n",
            "  Downloading trio_websocket-0.11.1-py3-none-any.whl (17 kB)\n",
            "Requirement already satisfied: certifi>=2021.10.8 in /usr/local/lib/python3.10/dist-packages (from selenium) (2024.7.4)\n",
            "Requirement already satisfied: typing_extensions>=4.9.0 in /usr/local/lib/python3.10/dist-packages (from selenium) (4.12.2)\n",
            "Requirement already satisfied: websocket-client>=1.8.0 in /usr/local/lib/python3.10/dist-packages (from selenium) (1.8.0)\n",
            "Requirement already satisfied: attrs>=23.2.0 in /usr/local/lib/python3.10/dist-packages (from trio~=0.17->selenium) (23.2.0)\n",
            "Requirement already satisfied: sortedcontainers in /usr/local/lib/python3.10/dist-packages (from trio~=0.17->selenium) (2.4.0)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.10/dist-packages (from trio~=0.17->selenium) (3.7)\n",
            "Collecting outcome (from trio~=0.17->selenium)\n",
            "  Downloading outcome-1.3.0.post0-py2.py3-none-any.whl (10 kB)\n",
            "Requirement already satisfied: sniffio>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from trio~=0.17->selenium) (1.3.1)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from trio~=0.17->selenium) (1.2.1)\n",
            "Collecting wsproto>=0.14 (from trio-websocket~=0.9->selenium)\n",
            "  Downloading wsproto-1.2.0-py3-none-any.whl (24 kB)\n",
            "Requirement already satisfied: pysocks!=1.5.7,<2.0,>=1.5.6 in /usr/local/lib/python3.10/dist-packages (from urllib3[socks]<3,>=1.26->selenium) (1.7.1)\n",
            "Collecting h11<1,>=0.9.0 (from wsproto>=0.14->trio-websocket~=0.9->selenium)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: outcome, h11, wsproto, trio, trio-websocket, selenium\n",
            "Successfully installed h11-0.14.0 outcome-1.3.0.post0 selenium-4.22.0 trio-0.26.0 trio-websocket-0.11.1 wsproto-1.2.0\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "import chromedriver_autoinstaller\n",
        "from selenium import webdriver\n",
        "from bs4 import BeautifulSoup\n",
        "import re\n",
        "import threading"
      ],
      "metadata": {
        "id": "0OFVW-6fjfdJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_soup(url):\n",
        "  chrome_options = webdriver.ChromeOptions()\n",
        "  chrome_options.add_argument('--headless')\n",
        "  chrome_options.add_argument('--no-sandbox')\n",
        "  chrome_options.add_argument('--disable-dev-shm-usage')\n",
        "\n",
        "  driver = webdriver.Chrome(options=chrome_options)\n",
        "\n",
        "  driver.get(url)\n",
        "\n",
        "  driver.implicitly_wait(1)\n",
        "\n",
        "  soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
        "\n",
        "  driver.quit()\n",
        "\n",
        "  return soup"
      ],
      "metadata": {
        "id": "gtFcpiSajkP-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 2 Options\n",
        "# 1. The page is found and is automatically opened\n",
        "# 2. The page is not found due to some kind of error and the first link in the search is taken\n",
        "def search_for_page(search_term):\n",
        "  '''\n",
        "  input: search_term - (string) what you're looking for\n",
        "  output: url - (string) the url of the page of results you're looking for\n",
        "  '''\n",
        "  # I'm just going to be lazy and add an \"i\" at the end of everything so everything gets kicked to the search page by default\n",
        "  url = f'https://minecraft.wiki/w/Special:Search?search={search_term.replace(\" \", \"+\")}i'\n",
        "\n",
        "  soup = get_soup(url)\n",
        "  url_addition = soup.find(\"a\", {\"data-serp-pos\": \"0\"})[\"href\"]\n",
        "  url = f'https://minecraft.wiki{url_addition}'\n",
        "\n",
        "  return url"
      ],
      "metadata": {
        "id": "HiA_Jls0kXch"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_info_box(soup):\n",
        "  info_box = soup.find(\"div\", {\"class\": \"notaninfobox\"})\n",
        "  info = {}\n",
        "\n",
        "  # Start by Grabbing all the top-of-table information\n",
        "  info[\"name\"] = info_box.find(\"div\", {\"class\": \"mcwiki-header infobox-title\"}).text.strip()\n",
        "  info[\"image_url\"] = \"https://minecraft.wiki\" + info_box.find(\"div\", {\"class\": \"infobox-imagearea animated-container\"}).find(\"img\")[\"src\"]\n",
        "\n",
        "  # Ok now we can grab the info from each table section\n",
        "  info[\"details\"] = {}\n",
        "  table = info_box.find(\"table\", {\"class\": \"infobox-rows\"})\n",
        "  table_rows = table.find_all(\"tr\")\n",
        "  for row in table_rows:\n",
        "    key = row.find(\"th\")\n",
        "    if key is None:\n",
        "      continue\n",
        "    value = row.find(\"td\")\n",
        "    if value is None:\n",
        "      continue\n",
        "    info[\"details\"][key.text.strip()] = value.text.strip()\n",
        "\n",
        "  return info"
      ],
      "metadata": {
        "id": "m-ObjS4--hcQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_main_paragraph(soup):\n",
        "  main_paragraph = soup.find(\"div\", {\"class\": \"mw-body-content mw-content-ltr\"})\n",
        "  main_paragraph = main_paragraph.find_all([\"p\", \"h2\", \"h3\"])\n",
        "\n",
        "\n",
        "  tables = soup.find_all(\"table\")\n",
        "  paragraphs_in_tables = []\n",
        "  for table in tables:\n",
        "    paragraphs_in_tables.extend(table.find_all(\"p\"))\n",
        "\n",
        "  filtered = [el for el in main_paragraph if el.name == 'h2' or el not in paragraphs_in_tables]\n",
        "  main_paragraph = [el.text.strip() for el in filtered]\n",
        "  return main_paragraph"
      ],
      "metadata": {
        "id": "TM-fb9B7JAIm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3. Throw Everything into ChatGPT"
      ],
      "metadata": {
        "id": "uqaA6xCZQP39"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install openai"
      ],
      "metadata": {
        "id": "NGUB8_qiQVXt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "447f773c-281f-4b70-e86b-129f18c539f4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting openai\n",
            "  Downloading openai-1.35.14-py3-none-any.whl (328 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m328.5/328.5 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai) (1.7.0)\n",
            "Collecting httpx<1,>=0.23.0 (from openai)\n",
            "  Downloading httpx-0.27.0-py3-none-any.whl (75 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.6/75.6 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from openai) (2.8.2)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai) (4.66.4)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.7 in /usr/local/lib/python3.10/dist-packages (from openai) (4.12.2)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (3.7)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (1.2.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (2024.7.4)\n",
            "Collecting httpcore==1.* (from httpx<1,>=0.23.0->openai)\n",
            "  Downloading httpcore-1.0.5-py3-none-any.whl (77 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.20.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (2.20.1)\n",
            "Installing collected packages: httpcore, httpx, openai\n",
            "Successfully installed httpcore-1.0.5 httpx-0.27.0 openai-1.35.14\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from openai import OpenAI\n",
        "client = OpenAI(api_key=api_key)"
      ],
      "metadata": {
        "id": "PH9LtoSMvpNr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def make_chatgpt_request(prompt):\n",
        "  chat_completion = client.chat.completions.create(\n",
        "      model=\"gpt-3.5-turbo\",\n",
        "      messages=[\n",
        "          {\n",
        "              \"role\": \"user\",\n",
        "              \"content\": prompt\n",
        "          }\n",
        "      ]\n",
        "  )\n",
        "  return chat_completion.choices[0].message.content"
      ],
      "metadata": {
        "id": "r9r5Q9XGxE5b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "basic_feature_extraction = '''You are an AI designed to assist with extracting specific features from user requests related to the game Minecraft. Your task is to analyze the user query (delimited by triple backticks) and extract two key pieces of information:\n",
        "\n",
        "Subject: Identify the main subject of the sentence. This is typically a Minecraft item, entity, block, or structure (full names only).\n",
        "Summary: Provide a brief summary of the specific information or request that the user wants to know about the subject. Include any information that may be important.\n",
        "Here are some examples to guide you:\n",
        "\n",
        "Example 1:\n",
        "User query: \"How do I find diamonds in Minecraft?\n",
        "Subject: \"diamonds\"\n",
        "Summary: \"How to find\"\n",
        "\n",
        "Example 2:\n",
        "User query: \"What are the best enchantments for a sword?\"\n",
        "Subject: \"sword\"\n",
        "Summary: \"best enchantments\"\n",
        "\n",
        "When processing each query, please answer with only the subject and the summary, separated by a backslash.\n",
        "\n",
        "```\n",
        "\n",
        "'''\n",
        "\n",
        "generate_output = '''You are an AI designed to extract specific answers from provided text based on a given summary. Your task is to read the given paragraphs and answer the summary as accurately as possible using the information from the text.\n",
        "Do not change anything in the summary.\n",
        "\n",
        "Here is the format you should follow:\n",
        "\n",
        "Summary: This is a brief statement or question that you need to answer.\n",
        "Paragraphs: These are the detailed texts from which you will extract the necessary information to answer the summary.\n",
        "Answer: This is the accurate and concise response to the summary based on the provided paragraphs.\n",
        "Use the following example as a guide:\n",
        "\n",
        "Example:\n",
        "Summary: benefits of a beacon\n",
        "Paragraphs: Beacons are powerful items in Minecraft that provide various status effects to players within a certain radius. When activated, beacons can grant players speed, haste, resistance, jump boost, or strength. Additionally, a fully powered beacon can give regeneration or a secondary status effect. Beacons are often used in bases to enhance player abilities and provide strategic advantages during combat or resource gathering.\n",
        "Answer: Beacons provide status effects such as speed, haste, resistance, jump boost, and strength. Fully powered beacons can also give regeneration or a secondary effect, enhancing player abilities and providing strategic advantages in combat and resource gathering.\n",
        "\n",
        "When processing each query, please answer with only the answer to the summary.\n",
        "\n",
        "The summary and paragraphs (respectively) are defined below, delimited by triple backticks.\n",
        "```\n",
        "\n",
        "'''"
      ],
      "metadata": {
        "id": "KM4r-XTxxPFQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def prompt(prompt):\n",
        "  summary = make_chatgpt_request(basic_feature_extraction + prompt + \"\\n```\")\n",
        "  summary = summary.strip(\"\\'\\\"\").split(\"\\n\")\n",
        "  summary = [summary[0].strip(\"Subject: \").strip('\"'),summary[1].strip(\"Summary: \").strip('\"')]\n",
        "\n",
        "  subject = summary[0]\n",
        "  summary = summary[1]\n",
        "\n",
        "  info = [None]\n",
        "  paragraphs = [None]\n",
        "\n",
        "  threads = [\n",
        "      threading.Thread(target=lambda: info.__setitem__(0, extract_info_box(soup))),\n",
        "      threading.Thread(target=lambda: paragraphs.__setitem__(0, extract_main_paragraph(soup)))\n",
        "  ]\n",
        "\n",
        "  url = search_for_page(subject)\n",
        "  soup = get_soup(url)\n",
        "\n",
        "  threads[0].start()\n",
        "  threads[1].start()\n",
        "\n",
        "  threads[0].join()\n",
        "  threads[1].join()\n",
        "\n",
        "  summary = make_chatgpt_request(generate_output + summary + \"\\n```\" + \"\\n\".join(info[0]) + \"\\n\".join(paragraphs[0]))\n",
        "  return summary"
      ],
      "metadata": {
        "id": "zaMdD7Du07fS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def main():\n",
        "  print(prompt(input(\"What would you like to ask? \")))"
      ],
      "metadata": {
        "id": "Ur84CyC81ar5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XfJzW196hVJ-",
        "outputId": "8d888080-f09a-48f7-e314-5065b9ec703c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "What would you like to ask? What is dirt?\n",
            "Summary: What is dirt used for in Minecraft?\n",
            "\n",
            "Answer: Dirt is primarily used for farming in Minecraft, but due to its abundance, it can also be used as a readily available building block.\n"
          ]
        }
      ]
    }
  ]
}